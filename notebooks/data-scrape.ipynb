{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get path to the repo directory\n",
    "dir_path = \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read this article's HTML into Python, which we'll do by utilizing the requests library. (If you don't have it, you can use the command line to execute pip install requests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an URL object\n",
    "url = 'https://projects.oregonlive.com/indigent-burials/indigent.json'\n",
    "# Create object page\n",
    "page = requests.get(url)\n",
    "\n",
    "# print(page.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>BEIGHTS, Karl Wesleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>CATER, Jon Leslie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>CRAFT, Michael David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>DIETZ, Wendenlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>DILKA, Richard Earl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                  name\n",
       "0 2000-01-01  BEIGHTS, Karl Wesleu\n",
       "1 2000-01-01     CATER, Jon Leslie\n",
       "2 2000-01-01  CRAFT, Michael David\n",
       "3 2000-01-01      DIETZ, Wendenlin\n",
       "4 2000-01-01   DILKA, Richard Earl"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tables\n",
    "oregon = pd.read_json(url)\n",
    "oregon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6554 entries, 0 to 6553\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    6554 non-null   datetime64[ns]\n",
      " 1   name    6554 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 102.5+ KB\n"
     ]
    }
   ],
   "source": [
    "oregon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon['date'] = pd.to_datetime(oregon['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output collected data to the \"web-scraping\" folder\n",
    "oregon.to_csv((dir_path + \"../web-scraping/oregon/the-unclaimed.csv\"), index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "The Beautiful Soup 4 package, a well-known Python web scraping library, will be used to parse the HTML. You can pip install beautifulsoup4 from the command line if you don't already have it.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.dignitymemorial.com/plan-funeral-cremation/veterans/homeless-veterans-program/21-homeless-vet-burials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The code above retrieves our website from the URL and saves the outcome in a \"response\" object called r. **The text attribute of that response object has the same HTML code as the source code displayed in our web browser:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" class=\"no-js\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"><script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info = {\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\",\"licenseKey\":\"eac7771f5a\",\"applicationID\":\"1360028078\",\"transactionName\":\"ZldUMkRSWUUEVBFdWV8dezB1HGRfEVIGW0RUcVkIQkFYWglSFxt/X1ZTHg==\",\"queueTime\":0,\"applicationTime\":882,\"agent\":\"\",\"atts\":\"\"}</script><script type=\"text/\n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters of the HTML\n",
    "print(r.text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below translates the HTML (stored in r.text) into a particular soup object that the Beautiful Soup library can recognize. In other words, HTML is being read and the structure of the HTML is being interpreted by Beautiful Soup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering all the data\n",
    "\n",
    "We will now begin constructing our dataset by utilizing the patterns we identified in the webpage structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all('h2')\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This code looks through the soup object for every < h2 > tags. It provides the search results in a unique Beautiful Soup object known as a Result Set.\n",
    "\n",
    "* results behaves like a Python list, enabling us to determine its length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given how long the article is, there are 21 results, which seems appropriate. (Whether we didn't think this number made sense, we would look more closely at the HTML to see if our theories about its patterns weren't accurate.)\n",
    "\n",
    "* For a closer look at the top three outcomes, we may also slice the object like a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2><a class=\"basic-link\" href=\"https://www.dignitymemorial.com/obituaries/phoenix-az/will-shegog-8179335\" rel=\"noopener noreferrer\" target=\"_blank\">Will Melvin Shegog, U.S. Air Force</a></h2>,\n",
       " <h2><a class=\"basic-link\" href=\"https://www.dignitymemorial.com/obituaries/knoxville-tn/ronnie-lundy-8141440\" rel=\"noopener noreferrer\" target=\"_blank\">Ronnie Joe Lundy, U.S. Army</a></h2>,\n",
       " <h2><a class=\"basic-link\" href=\"https://www.dignitymemorial.com/obituaries/lexington-sc/joseph-williams-8710549\" rel=\"noopener noreferrer\" target=\"_blank\">Joseph Lorenzo Williams, U.S. Army</a></h2>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll likewise make sure the last record in the article and the last result in this object match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2>\n",
       "Ronald Baker Thomas, U.S. Army\n",
       "</h2>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretty good looking!**\n",
    "\n",
    "* All 21 entries have now been gathered, but to give the dataset some structure, we still need to divide each record into its three parts (date, name, and organization).\n",
    "\n",
    "* To make things easier, we'll begin by just manipulating the first record in the results object, and subsequently we'll change our code to make use of a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2><a class=\"basic-link\" href=\"https://www.dignitymemorial.com/obituaries/phoenix-az/will-shegog-8179335\" rel=\"noopener noreferrer\" target=\"_blank\">Will Melvin Shegog, U.S. Air Force</a></h2>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the name\n",
    "first_result = results[0]\n",
    "first_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that first result appears to be a Python string, there are no quote marks surrounding it. It is actually a different unique Beautiful Soup object (called a \"Tag\") with specific methods and attributes.\n",
    "\n",
    "* We may access its text attribute, which does indeed yield a typical Python string, since we want to extract the text that is included between the opening and closing tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will Melvin Shegog, U.S. Air Force'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.text\n",
    "#     or \n",
    "# first_result.find('a').text[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's slice through this list to get the initial component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will Melvin Shegog'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.text.split(',')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a for loop to put all the strings into the list\n",
    "* To repeat this procedure over all 21 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Will Melvin Shegog',\n",
       " 'Ronnie Joe Lundy',\n",
       " 'Joseph Lorenzo Williams',\n",
       " 'Danny Rollin Ballantyne',\n",
       " 'George Charles Babcock',\n",
       " 'James Miske',\n",
       " 'Stephen Jerald Spicer',\n",
       " 'Howard Nicholas Warren',\n",
       " 'Charles Bradley Fox',\n",
       " 'James David Ellis',\n",
       " 'Frank Harmon Wilson',\n",
       " 'Wesley Russell',\n",
       " 'Arnold Martin Klechka',\n",
       " 'James Michael Farrar',\n",
       " 'Charles Joseph Burnett',\n",
       " 'Robert Lee Baker',\n",
       " 'Stephen Sebastian Cunningham',\n",
       " 'George Shaw',\n",
       " 'Richard Lindsay Butterfield',\n",
       " 'Gary Lynn Andrews',\n",
       " 'Ronald Baker Thomas']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_head = []\n",
    "# for i in soup.find_all('h2'):\n",
    "for i in results:\n",
    " title = i.text.split(',')[0].strip()\n",
    " name_head.append(title)\n",
    "name_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U.S. Air Force',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Marine Corps',\n",
       " 'U.S. Army',\n",
       " 'U.S. Navy',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Marine Corps',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army',\n",
       " 'Jr.',\n",
       " 'U.S. Army',\n",
       " 'U.S. Coast Guard',\n",
       " 'U.S. Marine Corps',\n",
       " 'U.S. Army',\n",
       " 'U.S. Army']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_title = []\n",
    "\n",
    "for x in results:\n",
    "  # This list can be sliced to extract the second element\n",
    "  detail = x.text.split(',')[1].strip()\n",
    "  main_title.append(detail)\n",
    "main_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Date\n",
    "* The approach is to look for surrounding tags, just like we did when we extracted the name but this time accessing specific atributes of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = soup.find_all('div', class_ = 'row row-band one-col')\n",
    "records = []\n",
    "for event in events:\n",
    "    event_name = event.find_all('p')[1]\n",
    "    # print(event_name.text)\n",
    "    records.append((event_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 21 results, thus we need to have 21 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look into the HTML more to see if our assumptions about the patterns in the HTML were accurate because there are 22 records, which doesn't seem reasonable.\n",
    "* Let's do a quick spot check of the first five records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>When family can’t be located or there are no resources to pay for a funeral service, a community of volunteer Dignity Memorial® funeral homes, veteran service groups, local medical examiners, coroners and veterans advocates step up to offer a proper and dignified funeral service.</p>,\n",
       " <p>March 24, 1960 – Feb. 15, 2019</p>,\n",
       " <p>Feb. 4, 1955 – Jan. 18, 2019</p>,\n",
       " <p>April 7, 1960 – April 1, 2019</p>,\n",
       " <p>Nov. 15, 1944 – April 30, 2019</p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a same way, we'll confirm that the final result in this object corresponds to the final entry in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "Jan. 3, 1946 – Sept. 8, 2019\n",
       "</p>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last record in the article matches the last result in this object, we must remove the additional records at index zero which is not part of the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_record = records[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>March 24, 1960 – Feb. 15, 2019</p>,\n",
       " <p>Feb. 4, 1955 – Jan. 18, 2019</p>,\n",
       " <p>April 7, 1960 – April 1, 2019</p>,\n",
       " <p>Nov. 15, 1944 – April 30, 2019</p>,\n",
       " <p>Feb. 17, 1940 – June 4, 2019</p>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_record[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "Jan. 3, 1946 – Sept. 8, 2019\n",
       "</p>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_record[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks reasonable!\n",
    "* Now we can build a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['March 24, 1960 – Feb. 15, 2019',\n",
       " 'Feb. 4, 1955 – Jan. 18, 2019',\n",
       " 'April 7, 1960 – April 1, 2019',\n",
       " 'Nov. 15, 1944 – April 30, 2019',\n",
       " 'Feb. 17, 1940 – June 4, 2019',\n",
       " 'Dec. 21, 1944 – May 26, 2019',\n",
       " 'April 18, 1947 - June 14, 2019',\n",
       " 'June 15, 1949 - July 16, 2019',\n",
       " 'Oct. 26, 1958 – Oct. 7, 2018',\n",
       " 'July 28, 1943-July 23, 2018',\n",
       " 'August 22, 1946-August 3, 2018',\n",
       " 'July 28, 1942 – Sept. 14, 2018',\n",
       " 'April 15, 1947 – Oct. 10, 2018',\n",
       " 'August 1, 1947 – Oct. 2, 2018',\n",
       " 'Nov. 20, 1946 – Oct. 16, 2018',\n",
       " 'March 15, 1948 – Dec. 10, 2018',\n",
       " 'Jan. 25, 1950 – Dec. 27, 2018',\n",
       " 'Jan. 24, 1951 – March 6, 2019',\n",
       " 'June 14, 1939 – April 4, 2019',\n",
       " 'August 24, 1951 – August 14, 2019',\n",
       " 'Jan. 3, 1946 – Sept. 8, 2019']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_head = []\n",
    "\n",
    "for elt in date_record:\n",
    "    time = elt.text.strip()\n",
    "    date_head.append(time)\n",
    "date_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so after building a for loop and adding all the strings to the lists, the next step is to construct a data frame from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>organization</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Will Melvin Shegog</td>\n",
       "      <td>U.S. Air Force</td>\n",
       "      <td>March 24, 1960 – Feb. 15, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronnie Joe Lundy</td>\n",
       "      <td>U.S. Army</td>\n",
       "      <td>Feb. 4, 1955 – Jan. 18, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Lorenzo Williams</td>\n",
       "      <td>U.S. Army</td>\n",
       "      <td>April 7, 1960 – April 1, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Danny Rollin Ballantyne</td>\n",
       "      <td>U.S. Marine Corps</td>\n",
       "      <td>Nov. 15, 1944 – April 30, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George Charles Babcock</td>\n",
       "      <td>U.S. Army</td>\n",
       "      <td>Feb. 17, 1940 – June 4, 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name       organization                            date\n",
       "0       Will Melvin Shegog     U.S. Air Force  March 24, 1960 – Feb. 15, 2019\n",
       "1         Ronnie Joe Lundy          U.S. Army    Feb. 4, 1955 – Jan. 18, 2019\n",
       "2  Joseph Lorenzo Williams          U.S. Army   April 7, 1960 – April 1, 2019\n",
       "3  Danny Rollin Ballantyne  U.S. Marine Corps  Nov. 15, 1944 – April 30, 2019\n",
       "4   George Charles Babcock          U.S. Army    Feb. 17, 1940 – June 4, 2019"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"name\": name_head, \n",
    "    \"organization\": main_title,\n",
    "    \"date\": date_head})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export To CSV\n",
    "\n",
    "When the data frame is complete, the next thing we can do is export it in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output gathered data to the \"web-scraping\" folder\n",
    "df.to_csv(dir_path + '../web-scraping/dignity-memorial/veterans.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "396ec3599db068b730f3c31fcff11d8f15ee156b078a9c463ed3d59b4ce6130a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
